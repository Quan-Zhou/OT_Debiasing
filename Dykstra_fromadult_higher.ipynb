{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "def normialise(tem_dist):\n",
    "    return [tem_dist[i]/sum(tem_dist) for i in range(len(tem_dist))]\n",
    "\n",
    "def tmp_generator(gamma_dict,num,q_dict,q_num,L):\n",
    "    bin=gamma_dict[0].shape[0]\n",
    "    if q_num<=0:\n",
    "        q=np.matrix(np.ones((bin,bin)))\n",
    "    else:\n",
    "        q=q_dict[q_num]\n",
    "    tmp_gamma=np.zeros((bin,bin))\n",
    "    tmp_q=np.zeros((bin,bin))\n",
    "    for i in range(bin):\n",
    "        for j in range(bin):\n",
    "            tmp_gamma[i,j]=q.item(i,j)*gamma_dict[num-1].item(i,j)*gamma_dict[num-L-1].item(i,j)/gamma_dict[num-L].item(i,j)\n",
    "            tmp_q[i,j]=q.item(i,j)*gamma_dict[num-L-1].item(i,j)/gamma_dict[num-L].item(i,j)\n",
    "    return np.matrix(tmp_gamma),np.matrix(tmp_q)     \n",
    "\n",
    "def assess(bin,f,g,C,V,output):\n",
    "    output=output.A1.reshape((bin,bin))\n",
    "    print('sum of violation of f:',sum(abs(np.sum(output,1)-f)))\n",
    "    print('sum of violation of g:',sum(abs(np.sum(output,0)-g)))\n",
    "    print('total cost:',sum(sum(output*C)))\n",
    "    print('entropy:',sum(sum(-output*np.log(output+0.1**3))))\n",
    "    print('tr violation:',sum(abs(output.T@V)))\n",
    "    print('============================================')\n",
    "\n",
    "def plots(x_range,g,f,output):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    gs = fig.add_gridspec(2, 2, width_ratios=(4,1), height_ratios=(1,4),left=0.1,right=0.9,bottom=0.1, top=0.9,wspace=0,hspace=0)\n",
    "    # Create the Axes.\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    ax.pcolormesh(x_range, x_range, output, cmap='Blues')\n",
    "    ax.set_xlabel(r'supp($X$)',fontsize=10)\n",
    "    ax.set_ylabel(r'supp($\\tilde{X}$)',fontsize=10)#\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax_histx = fig.add_subplot(gs[0, 0], sharex=ax) \n",
    "    ax_histy = fig.add_subplot(gs[1, 1], sharey=ax)\n",
    "    #ax_histx.set_title(r'$Pr[x]$',rotation='horizontal')\n",
    "    #ax_histy.set_title(r'$Pr[\\tilde{x}]$')\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histx.tick_params(axis=\"y\", labelleft=False)\n",
    "    ax_histy.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "    ax_histx.plot(x_range,g,color='tab:blue')\n",
    "    ax_histy.plot(f,x_range,color='tab:green') \n",
    "    return fig\n",
    "\n",
    "def v_value(x0,x1,x):\n",
    "    if x != 0:\n",
    "        return (x0-x1)/x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def newton(fun,dfun,a, stepmax, tol):\n",
    "    if abs(fun(a))<=tol: return a\n",
    "    for step in range(1, stepmax+1):\n",
    "        b=a-fun(a)/dfun(a)\n",
    "        if abs(fun(b))<=tol:\n",
    "            return b\n",
    "        else:\n",
    "            a = b\n",
    "    return b \n",
    "\n",
    "# simplist\n",
    "def baseline(C,e,px,ptx,V,K):\n",
    "    bin=len(px)\n",
    "    bbm1=np.matrix(np.ones(bin)).T\n",
    "    #I=np.where(~(V==0))[0].tolist()\n",
    "    xi=np.exp(-C/e)\n",
    "    gamma_classic=dict()\n",
    "    gamma_classic[0]=np.matrix(xi+1.0e-9)\n",
    "    for repeat in range(K):\n",
    "        gamma_classic[1+2*repeat]=np.matrix(np.diag((px/(gamma_classic[2*repeat] @ bbm1)).A1))@gamma_classic[2*repeat] #np.diag(dist['x']/sum(gamma_classic.T))@gamma_classic\n",
    "        gamma_classic[2+2*repeat]=gamma_classic[1+2*repeat]@np.matrix(np.diag((ptx/(gamma_classic[1+2*repeat].T @ bbm1)).A1))\n",
    "\n",
    "    assess(bin,dist['x'],dist['t_x'],C,V,gamma_classic[2*K])\n",
    "    return gamma_classic\n",
    "\n",
    "# our method | total repair\n",
    "def total_repair(C,e,px,ptx,V,K):\n",
    "    bin=len(px)\n",
    "    bbm1=np.matrix(np.ones(bin)).T\n",
    "    I=np.where(~(V==0))[0].tolist()\n",
    "    xi=np.exp(-C/e)\n",
    "    gamma_dict=dict()\n",
    "    gamma_dict[0]=np.matrix(xi+1.0e-9)\n",
    "    gamma_dict[1]=np.matrix(np.diag((px/(gamma_dict[0] @ bbm1)).A1))@gamma_dict[0]\n",
    "    gamma_dict[2]=gamma_dict[1]@np.matrix(np.diag((ptx/(gamma_dict[1].T @ bbm1)).A1))\n",
    "    # step 3\n",
    "    J=np.where(~((gamma_dict[2].T @ V).A1 ==0))[0].tolist()\n",
    "    nu=np.zeros(bin)\n",
    "    gamma_dict[3]=np.copy(gamma_dict[2])\n",
    "    for j in J:\n",
    "        fun = lambda z: sum(gamma_dict[2].item(i,j)*V.item(i)*np.exp(z*V.item(i)) for i in I)\n",
    "        dfun = lambda z: sum(gamma_dict[2].item(i,j)*(V.item(i))**2*np.exp(z*V.item(i)) for i in I)\n",
    "        nu = newton(fun,dfun,0.5,stepmax = 25,tol = 1.0e-3) #bisection(fun, -50,50, stepmax = 25, tol = 1.0e-3)\n",
    "        for i in I:\n",
    "            gamma_dict[3][i,j]=np.exp(nu*V.item(i))*gamma_dict[2].item(i,j)\n",
    "    gamma_dict[3]=np.matrix(gamma_dict[3])\n",
    "\n",
    "    #=========================\n",
    "    L=3\n",
    "    q_dict=dict()\n",
    "    for loop in range(1,K):\n",
    "        tmp,q_dict[(loop-1)*L+1]=tmp_generator(gamma_dict,loop*L+1,q_dict,(loop-2)*L+1,L) #np.matrix(gamma_dict[3].A1*gamma_dict[0].A1/gamma_dict[1].A1)\n",
    "        gamma_dict[loop*L+1]=np.matrix(np.diag((px/(tmp @ bbm1)).A1))@tmp\n",
    "\n",
    "        tmp,q_dict[(loop-1)*L+2]=tmp_generator(gamma_dict,loop*L+2,q_dict,(loop-2)*L+2,L)  #np.matrix(gamma_dict[4].A1*gamma_dict[1].A1/gamma_dict[2].A1)\n",
    "        gamma_dict[loop*L+2]=tmp@np.matrix(np.diag((ptx/(tmp.T @ bbm1)).A1))\n",
    "\n",
    "        # step 3\n",
    "        tmp,q_dict[(loop-1)*L+3]=tmp_generator(gamma_dict,loop*L+3,q_dict,(loop-2)*L+3,L)  #np.matrix(gamma_dict[5].A1*gamma_dict[2].A1/gamma_dict[3].A1)\n",
    "        J=np.where(~((abs(np.matrix(tmp).T @ V).A1)<=1.0e-5))[0].tolist()\n",
    "        gamma_dict[loop*L+3]=np.copy(tmp)\n",
    "        for j in J:\n",
    "            fun = lambda z: sum(tmp.item(i,j)*V.item(i)*np.exp(z*V.item(i)) for i in I)\n",
    "            dfun = lambda z: sum(tmp.item(i,j)*(V.item(i))**2*np.exp(z*V.item(i)) for i in I)\n",
    "            nu = newton(fun,dfun,0.5,stepmax = 25,tol = 1.0e-5) \n",
    "            for i in I:\n",
    "                gamma_dict[loop*L+3][i,j]=np.exp(nu*V.item(i))*tmp.item(i,j)\n",
    "        gamma_dict[loop*L+3]=np.matrix(gamma_dict[loop*L+3])\n",
    "\n",
    "    assess(bin,dist['x'],dist['t_x'],C,V,gamma_dict[K*L])\n",
    "    return gamma_dict\n",
    "\n",
    "# our method | partial repair\n",
    "def partial_repair(C,e,px,ptx,V,theta_scale,K):\n",
    "    bin=len(px)\n",
    "    bbm1=np.matrix(np.ones(bin)).T\n",
    "    I=np.where(~(V==0))[0].tolist()\n",
    "    xi=np.exp(-C/e)\n",
    "    theta=bbm1*theta_scale\n",
    "    gamma_dict=dict()\n",
    "    gamma_dict[0]=np.matrix(xi+1.0e-9)\n",
    "    gamma_dict[1]=np.matrix(np.diag((px/(gamma_dict[0] @ bbm1)).A1))@gamma_dict[0]\n",
    "    gamma_dict[2]=gamma_dict[1]@np.matrix(np.diag((ptx/(gamma_dict[1].T @ bbm1)).A1))\n",
    "    # step 3\n",
    "    Jplus=np.where(~((gamma_dict[2].T @ V).A1 <=theta.A1))[0].tolist()\n",
    "    Jminus=np.where(~((gamma_dict[2].T @ V).A1>=-theta.A1))[0].tolist()\n",
    "    gamma_dict[3]=np.copy(gamma_dict[2])\n",
    "    for j in Jplus:\n",
    "        fun = lambda z: sum(gamma_dict[2].item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)-theta.item(j)\n",
    "        dfun = lambda z: -sum(gamma_dict[2].item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
    "        nu = newton(fun,dfun,0.5,stepmax = 25,tol = 1.0e-3) #bisection(fun, -50,50, stepmax = 25, tol = 1.0e-3)\n",
    "        for i in I:\n",
    "            gamma_dict[3][i,j]=np.exp(-nu*V.item(i))*gamma_dict[2].item(i,j)\n",
    "    for j in Jminus:\n",
    "        fun = lambda z: sum(gamma_dict[2].item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)+theta.item(j)\n",
    "        dfun = lambda z: -sum(gamma_dict[2].item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
    "        nu = newton(fun,dfun,0.5,stepmax = 25,tol = 1.0e-3) #bisection(fun, -50,50, stepmax = 25, tol = 1.0e-3)\n",
    "        for i in I:\n",
    "            gamma_dict[3][i,j]=np.exp(-nu*V.item(i))*gamma_dict[2].item(i,j)\n",
    "    gamma_dict[3]=np.matrix(gamma_dict[3])\n",
    "\n",
    "    #=========================\n",
    "    L=3\n",
    "    q_dict=dict()\n",
    "    for loop in range(1,K):\n",
    "        tmp,q_dict[(loop-1)*L+1]=tmp_generator(gamma_dict,loop*L+1,q_dict,(loop-2)*L+1,L) #np.matrix(gamma_dict[3].A1*gamma_dict[0].A1/gamma_dict[1].A1)\n",
    "        gamma_dict[loop*L+1]=np.matrix(np.diag((px/(tmp @ bbm1)).A1))@tmp\n",
    "\n",
    "        tmp,q_dict[(loop-1)*L+2]=tmp_generator(gamma_dict,loop*L+2,q_dict,(loop-2)*L+2,L)  #np.matrix(gamma_dict[4].A1*gamma_dict[1].A1/gamma_dict[2].A1)\n",
    "        gamma_dict[loop*L+2]=tmp@np.matrix(np.diag((ptx/(tmp.T @ bbm1)).A1))\n",
    "\n",
    "        # step 3\n",
    "        tmp,q_dict[(loop-1)*L+3]=tmp_generator(gamma_dict,loop*L+3,q_dict,(loop-2)*L+3,L)  #np.matrix(gamma_dict[5].A1*gamma_dict[2].A1/gamma_dict[3].A1)\n",
    "        Jplus=np.where(~((np.matrix(tmp).T @ V).A1 <=theta.A1))[0].tolist()\n",
    "        Jminus=np.where(~((np.matrix(tmp).T @ V).A1>=-theta.A1))[0].tolist()\n",
    "        gamma_dict[loop*L+3]=np.copy(tmp)\n",
    "        for j in Jplus:\n",
    "            fun = lambda z: sum(tmp.item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)-theta.item(j)\n",
    "            dfun = lambda z: -sum(tmp.item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
    "            nu = newton(fun,dfun,0.5,stepmax = 25,tol = 1.0e-5) \n",
    "            for i in I:\n",
    "                gamma_dict[loop*L+3][i,j]=np.exp(-nu*V.item(i))*tmp.item(i,j)\n",
    "        for j in Jminus:\n",
    "            fun = lambda z: sum(tmp.item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)+theta.item(j)\n",
    "            dfun = lambda z: -sum(tmp.item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
    "            nu = newton(fun,dfun,0.5,stepmax = 25,tol = 1.0e-5) \n",
    "            for i in I:\n",
    "                gamma_dict[loop*L+3][i,j]=np.exp(-nu*V.item(i))*tmp.item(i,j)\n",
    "        gamma_dict[loop*L+3]=np.matrix(gamma_dict[loop*L+3])\n",
    "\n",
    "    assess(bin,dist['x'],dist['t_x'],C,V,gamma_dict[L*K])\n",
    "    return gamma_dict\n",
    "\n",
    "def empirical_distribution(sub,x_range):\n",
    "    bin=len(x_range)\n",
    "    distrition=np.zeros(bin)\n",
    "    for i in range(bin):\n",
    "        subset=sub[sub['X']==x_range[i]] #bin_value=x_range[i] #sub[(sub['X']>=bin_value)&(sub['X']<bin_value+width)]\n",
    "        if subset.shape[0]>0:\n",
    "            distrition[i]=sum(subset['W'])\n",
    "    if sum(distrition)>0:\n",
    "        return distrition/sum(distrition)\n",
    "    else:\n",
    "        return distrition\n",
    "\n",
    "def plot_rdist(rdist,x_range):\n",
    "    plt.plot(x_range,rdist['x'],label=r'$Pr[x]$',color='tab:blue')\n",
    "    plt.plot(x_range,rdist['x_0'],label=r'$Pr[x|s_0]$',alpha=0.3,color='tab:orange')\n",
    "    plt.plot(x_range,rdist['x_1'],label=r'$Pr[x|s_1]$',alpha=0.3,color='#9f86c0')\n",
    "    plt.ylabel('PMF',fontsize=14)\n",
    "    plt.xlabel(r'$supp(X)=supp(\\tilde{X})$',fontsize=20)\n",
    "    plt.legend()\n",
    "    return plt\n",
    "\n",
    "def DisparateImpact(X_test,y_pred):\n",
    "    dim=X_test.shape[1]-2\n",
    "    df_test=pd.DataFrame(np.concatenate((X_test,y_pred.reshape(-1,1)), axis=1),columns=[*range(dim)]+['S','W','f'])\n",
    "    numerator=sum(df_test[(df_test['S']==0)&(df_test['f']==1)]['W'])/sum(df_test[df_test['S']==0]['W'])\n",
    "    denominator=sum(df_test[(df_test['S']==1)&(df_test['f']==1)]['W'])/sum(df_test[df_test['S']==1]['W'])\n",
    "    return numerator/denominator\n",
    "    \n",
    "def rdata_analysis(rdata,x_range):\n",
    "    rdist=dict()\n",
    "    pivot=pd.pivot_table(rdata,index=list(chain(*[x_list])),values=['W'],aggfunc=[np.sum])[('sum','W')]\n",
    "    pivot0=pd.pivot_table(rdata[rdata['S']==0],index=list(chain(*[x_list])),values=['W'],aggfunc=[np.sum])[('sum','W')]\n",
    "    pivot1=pd.pivot_table(rdata[rdata['S']==1],index=list(chain(*[x_list])),values=['W'],aggfunc=[np.sum])[('sum','W')]\n",
    "    rdist['x']= np.array([pivot[i] for i in x_range])/sum([pivot[i] for i in x_range]) #empirical_distribution(rdata,x_range)\n",
    "    rdist['x_0']=np.array([pivot0[i] if i in list(pivot0.index) else 0 for i in x_range])/sum([pivot0[i] if i in list(pivot0.index) else 0 for i in x_range]) #empirical_distribution(rdata[rdata['S']==0],x_range)\n",
    "    rdist['x_1']=np.array([pivot1[i] if i in list(pivot1.index) else 0 for i in x_range])/sum([pivot1[i] if i in list(pivot1.index) else 0 for i in x_range]) #empirical_distribution(rdata[rdata['S']==1],x_range)\n",
    "    return rdist\n",
    "\n",
    "def c_generate_higher(x_range):\n",
    "    bin=len(x_range)\n",
    "    dim=len(x_range[0])\n",
    "    C=np.random.random((bin,bin))\n",
    "    for i in range(bin):\n",
    "        for j in range(bin):\n",
    "            C[i,j]=sum(abs(x_range[i][d]-x_range[j][d]) for d in range(dim))\n",
    "    return C\n",
    "\n",
    "def c_generate(x_range):\n",
    "    bin=len(x_range)\n",
    "    C=np.random.random((bin,bin))\n",
    "    for i in range(bin):\n",
    "        for j in range(bin):\n",
    "            C[i,j]=abs(x_range[i]-x_range[j]) \n",
    "    return C\n",
    "\n",
    "def projection(df,coupling_matrix,x_range,x_list):\n",
    "    bin=len(x_range)\n",
    "    dim=len(x_list)\n",
    "    data=df.groupby(by=list(chain(*[x_list,'S','Y'])),as_index=False).sum()# data column: x_list,S,Y,W\n",
    "    data=data[x_list+['S','W','Y']]\n",
    "    coupling=coupling_matrix.A1.reshape((bin,bin))\n",
    "    df_t=pd.DataFrame(columns=['X','S','W','Y'])\n",
    "    for i in range(data.shape[0]):\n",
    "        orig=data.iloc[i]\n",
    "        loc=np.where([x_range[i]==orig[0:dim].values for i in range(bin)])[0][0]\n",
    "        rows=np.nonzero(coupling[loc,:])[0]\n",
    "        sub_dict={'X':[x_range[r] for r in rows],'W':list(coupling[loc,rows]/(sum(coupling[loc,rows]))*orig[dim+1])}\n",
    "        sub=pd.DataFrame(data=sub_dict, index=rows)\n",
    "        sub['W']=coupling[loc,rows]/(sum(coupling[loc,rows]))*orig[dim+1]\n",
    "        sub['S']=orig[dim]\n",
    "        sub['Y']=orig[dim+2]\n",
    "        df_t=pd.concat([df_t,sub],ignore_index=True)#pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
    "    if dim>1:\n",
    "        for d in range(dim):\n",
    "            df_t[x_list[d]]=[df_t['X'][r][d] for r in range(df_t.shape[0])] #df_t['X'][:][d]\n",
    "    else:\n",
    "        df_t[x_list[0]]=df_t['X']\n",
    "\n",
    "    return df_t[x_list+['S','W','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0    2         State-gov   77516  Bachelors             13   \n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('C:/Users/zhouq/Documents/optimal_transport/adult_csv.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of violation of f: 0.005185398987376815\n",
      "sum of violation of g: 2.764817183791707e-16\n",
      "total cost: 0.3991361376558401\n",
      "entropy: 3.7109604430563325\n",
      "tr violation: [[0.27053001]]\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "coupling_matrix=baseline(C,e,px,ptx,V,K)[K*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of violation of f: 0.0036467884335666923\n",
      "sum of violation of g: 2.0415526907902048e-16\n",
      "total cost: 0.3659321530724333\n",
      "entropy: 2.9225917543694826\n",
      "tr violation: [[0.31370058]]\n",
      "============================================\n",
      "sum of violation of f: 0.003075720232100548\n",
      "sum of violation of g: 0.00035140190723314537\n",
      "total cost: 0.8463600221109463\n",
      "entropy: 3.217463869557872\n",
      "tr violation: [[0.15994331]]\n",
      "============================================\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m clf_base\u001b[39m=\u001b[39mRandomForestClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mfit(X_train_base[:,\u001b[39m0\u001b[39m:dim],y_train_base,sample_weight\u001b[39m=\u001b[39mX_train_base[:,dim\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     49\u001b[0m y_pred_base\u001b[39m=\u001b[39mclf_base\u001b[39m.\u001b[39mpredict(X_test[:,\u001b[39m0\u001b[39m:dim])\n\u001b[1;32m---> 50\u001b[0m new_row_base \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries({\u001b[39m'\u001b[39m\u001b[39mDI\u001b[39m\u001b[39m'\u001b[39m:DisparateImpact(X_test,y_pred_base),\n\u001b[0;32m     51\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mf1 macro\u001b[39m\u001b[39m'\u001b[39m:f1_score(y_test, y_pred_base, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     52\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mf1 micro\u001b[39m\u001b[39m'\u001b[39m:f1_score(y_test, y_pred_base, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     53\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mf1 weighted\u001b[39m\u001b[39m'\u001b[39m:f1_score(y_test, y_pred_base, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     54\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mbaseline\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     55\u001b[0m X_train_part\u001b[39m=\u001b[39mrdata_part2[x_list\u001b[39m+\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m     56\u001b[0m y_train_part\u001b[39m=\u001b[39mrdata_part2[\u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[134], line 225\u001b[0m, in \u001b[0;36mDisparateImpact\u001b[1;34m(X_test, y_pred)\u001b[0m\n\u001b[0;32m    223\u001b[0m numerator\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(df_test[(df_test[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m&\u001b[39m(df_test[\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m)][\u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m/\u001b[39m\u001b[39msum\u001b[39m(df_test[df_test[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    224\u001b[0m denominator\u001b[39m=\u001b[39m\u001b[39msum\u001b[39m(df_test[(df_test[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m&\u001b[39m(df_test[\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m)][\u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m/\u001b[39m\u001b[39msum\u001b[39m(df_test[df_test[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 225\u001b[0m \u001b[39mreturn\u001b[39;00m numerator\u001b[39m/\u001b[39;49mdenominator\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "x_list=['education-num','sex'] #\n",
    "dim=len(x_list)\n",
    "messydata=pd.read_csv('C:/Users/zhouq/Documents/optimal_transport/adult_csv.csv',usecols=x_list+['race','class'])\n",
    "messydata=messydata[(messydata['race']=='White')|(messydata['race']=='Black')]\n",
    "for col in ['race','class']+x_list:\n",
    "    messydata[col]=messydata[col].astype('category')\n",
    "cat_columns = messydata.select_dtypes(['category']).columns\n",
    "messydata[cat_columns]=messydata[cat_columns].apply(lambda x: x.cat.codes)\n",
    "messydata=messydata.rename(columns={'race':'S','class':'Y'}) #'education-num':'X1','hoursperweek':'X2',\n",
    "messydata['W']=1\n",
    "#x_range_full=dict()\n",
    "#for name in x_list:\n",
    "#    x_range_full[name]=np.arange(min(df[name]),max(df[name])+1,1)\n",
    "X=messydata[list(chain(*[x_list,'S','W']))].to_numpy()\n",
    "y=messydata['Y'].to_numpy()\n",
    "e=0.01\n",
    "K=200\n",
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','method'])\n",
    "for ignore in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    df=pd.DataFrame(np.concatenate((X_train,y_train.reshape(-1,1)), axis=1),columns=list(chain(*[x_list,'S','W','Y'])))\n",
    "    \n",
    "    x_range=list(pd.pivot_table(df,index=list(chain(*[x_list])),values=['W'],aggfunc=[np.sum])[('sum','W')].index) #[(i,j) for i in x_range_full[x_list[0]] for j in x_range_full[x_list[1]]]\n",
    "    dist=rdata_analysis(df,x_range)\n",
    "    bin=len(x_range)\n",
    "    if dim>1:\n",
    "        C=c_generate_higher(x_range)\n",
    "    else:\n",
    "        C=c_generate(x_range)\n",
    "    dist['t_x']=dist['x_0']*0.5+dist['x_1']*0.5\n",
    "    dist['v']=[v_value(dist['x_0'][i],dist['x_1'][i],dist['x'][i]) for i in range(bin)]\n",
    "    px=np.matrix(dist['x']).T\n",
    "    ptx=np.matrix(dist['t_x']).T\n",
    "    V=np.matrix(dist['v']).T\n",
    "\n",
    "    rdata_base=projection(df,baseline(C,e,px,ptx,V,K)[K*2],x_range,x_list)\n",
    "    rdata_part2=projection(df,partial_repair(C,e,px,ptx,V,1.0e-2,K)[K*3],x_range,x_list)\n",
    "\n",
    "    clf=RandomForestClassifier(max_depth=4).fit(X_train[:,0:dim],y_train,sample_weight=X_train[:,dim+1])\n",
    "    y_pred=clf.predict(X_test[:,0:dim])\n",
    "    new_row = pd.Series({'DI':DisparateImpact(X_test,y_pred),\n",
    "                        'f1 macro':f1_score(y_test, y_pred, average='macro'),\n",
    "                        'f1 micro':f1_score(y_test, y_pred, average='micro'),\n",
    "                        'f1 weighted':f1_score(y_test, y_pred, average='weighted'),\n",
    "                        'method':'origin'})\n",
    "    X_train_base=rdata_base[x_list+['S','W']].to_numpy()\n",
    "    y_train_base=rdata_base['Y'].to_numpy().astype('int8')\n",
    "    clf_base=RandomForestClassifier(max_depth=4).fit(X_train_base[:,0:dim],y_train_base,sample_weight=X_train_base[:,dim+1])\n",
    "    y_pred_base=clf_base.predict(X_test[:,0:dim])\n",
    "    new_row_base = pd.Series({'DI':DisparateImpact(X_test,y_pred_base),\n",
    "                    'f1 macro':f1_score(y_test, y_pred_base, average='macro'),\n",
    "                    'f1 micro':f1_score(y_test, y_pred_base, average='micro'),\n",
    "                    'f1 weighted':f1_score(y_test, y_pred_base, average='weighted'),\n",
    "                    'method':'baseline'})\n",
    "    X_train_part=rdata_part2[x_list+['S','W']].to_numpy()\n",
    "    y_train_part=rdata_part2['Y'].to_numpy().astype('int8')\n",
    "    clf_part= RandomForestClassifier(max_depth=4).fit(X_train_part[:,0:dim],y_train_part,sample_weight=X_train_part[:,dim+1])\n",
    "    y_pred_part=clf_part.predict(X_test[:,0:dim])\n",
    "    new_row_part = pd.Series({'DI':DisparateImpact(X_test,y_pred_part),\n",
    "                    'f1 macro':f1_score(y_test, y_pred_part, average='macro'),\n",
    "                    'f1 micro':f1_score(y_test, y_pred_part, average='micro'),\n",
    "                    'f1 weighted':f1_score(y_test, y_pred_part, average='weighted'),\n",
    "                    'method':'partial repair'})\n",
    "    report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_part.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education-num</th>\n",
       "      <th>age</th>\n",
       "      <th>S</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999978e-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.726550e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.319469e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.356417e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.770531e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21115</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000077e-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21116</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.268475e-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21117</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.164588e-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21118</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.623069e-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21119</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.373111e-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       education-num  age  S             W  Y\n",
       "0                  0    0  0  9.999978e-01  0\n",
       "1                  0    1  0  6.726550e-09  0\n",
       "2                  0    2  0  7.319469e-09  0\n",
       "3                  0    3  0  4.356417e-09  0\n",
       "4                  0    4  0  2.770531e-09  0\n",
       "...              ...  ... ..           ... ..\n",
       "21115             15    0  1  5.000077e-14  1\n",
       "21116             15    1  1  7.268475e-14  1\n",
       "21117             15    2  1  1.164588e-13  1\n",
       "21118             15    3  1  8.623069e-14  1\n",
       "21119             15    4  1  6.373111e-14  1\n",
       "\n",
       "[21120 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(range(bin),dist['x'])\n",
    "plt.plot(range(bin),dist['x_0'])\n",
    "plt.plot(range(bin),dist['x_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.439913</td>\n",
       "      <td>0.590745</td>\n",
       "      <td>0.777545</td>\n",
       "      <td>0.73333</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.439913</td>\n",
       "      <td>0.590745</td>\n",
       "      <td>0.777545</td>\n",
       "      <td>0.73333</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131852</td>\n",
       "      <td>0.510866</td>\n",
       "      <td>0.770655</td>\n",
       "      <td>0.694695</td>\n",
       "      <td>partial repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.436802</td>\n",
       "      <td>0.596207</td>\n",
       "      <td>0.781366</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.436802</td>\n",
       "      <td>0.596207</td>\n",
       "      <td>0.781366</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.236555</td>\n",
       "      <td>0.516974</td>\n",
       "      <td>0.774961</td>\n",
       "      <td>0.700461</td>\n",
       "      <td>partial repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.441021</td>\n",
       "      <td>0.583762</td>\n",
       "      <td>0.775661</td>\n",
       "      <td>0.729416</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.441021</td>\n",
       "      <td>0.583762</td>\n",
       "      <td>0.775661</td>\n",
       "      <td>0.729416</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.316652</td>\n",
       "      <td>0.506475</td>\n",
       "      <td>0.770224</td>\n",
       "      <td>0.692412</td>\n",
       "      <td>partial repair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DI  f1 macro  f1 micro f1 weighted          method\n",
       "0  0.439913  0.590745  0.777545     0.73333          origin\n",
       "1  0.439913  0.590745  0.777545     0.73333        baseline\n",
       "2  0.131852  0.510866  0.770655    0.694695  partial repair\n",
       "3  0.436802  0.596207  0.781366    0.738333          origin\n",
       "4  0.436802  0.596207  0.781366    0.738333        baseline\n",
       "5  0.236555  0.516974  0.774961    0.700461  partial repair\n",
       "6  0.441021  0.583762  0.775661    0.729416          origin\n",
       "7  0.441021  0.583762  0.775661    0.729416        baseline\n",
       "8  0.316652  0.506475  0.770224    0.692412  partial repair"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from functions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=200\n",
    "e=0.01\n",
    "\n",
    "var_list=['hoursperweek','age','capitalgain','capitalloss' ,'education-num'] #\n",
    "var_dim=len(var_list)\n",
    "pa='sex'\n",
    "pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "messydata=pd.read_csv(path+'/data/adult_csv.csv',usecols=var_list+[pa,'class'])\n",
    "messydata=messydata.rename(columns={pa:'S','class':'Y'})\n",
    "messydata['S']=messydata['S'].replace(pa_dict)\n",
    "messydata['Y']=messydata['Y'].replace({'>50K':1,'<=50K':0})\n",
    "messydata=messydata[(messydata['S']==1)|(messydata['S']==0)]\n",
    "for col in var_list+['S','Y']:\n",
    "    messydata[col]=messydata[col].astype('category')\n",
    "messydata['W']=1\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n"
     ]
    }
   ],
   "source": [
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "    dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.08:\n",
    "        x_list+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:165: RuntimeWarning: overflow encountered in exp\n",
      "  fun = lambda z: sum(tmp.item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)+theta.item(j)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:166: RuntimeWarning: overflow encountered in exp\n",
      "  dfun = lambda z: -sum(tmp.item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:33: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  b=a-fun(a)/dfun(a)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:197: RuntimeWarning: invalid value encountered in divide\n",
      "  rdist['x']= np.array([pivot[i] for i in x_range])/sum([pivot[i] for i in x_range]) #empirical_distribution(rdata,x_range)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:200: RuntimeWarning: invalid value encountered in divide\n",
      "  rdist['x_0']=np.array([pivot0[i] if i in list(pivot0.index) else 0 for i in x_range])/sum([pivot0[i] if i in list(pivot0.index) else 0 for i in x_range]) #empirical_distribution(rdata[rdata['S']==0],x_range)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  rdist['x_1']=np.array([pivot1[i] if i in list(pivot1.index) else 0 for i in x_range])/sum([pivot1[i] if i in list(pivot1.index) else 0 for i in x_range]) #empirical_distribution(rdata[rdata['S']==1],x_range)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 79\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# new_row_part2=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part2),\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#                     'f1 macro':f1_score(df_test['Y'], y_pred_part2, average='macro',sample_weight=df_test['W']),\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#                     'f1 micro':f1_score(df_test['Y'], y_pred_part2, average='micro',sample_weight=df_test['W']),\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#                     'f1 weighted':f1_score(df_test['Y'], y_pred_part2, average='weighted',sample_weight=df_test['W']),\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m#                     'TV distance':tv_part2,'method':'partial repair2'})\u001b[39;00m\n\u001b[0;32m     74\u001b[0m new_row_part3\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDI\u001b[39m\u001b[38;5;124m'\u001b[39m:DisparateImpact_postprocess(df_test,y_pred_part3),\n\u001b[0;32m     75\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 macro\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred_part3, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m,sample_weight\u001b[38;5;241m=\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     76\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 micro\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred_part3, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m,sample_weight\u001b[38;5;241m=\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     77\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 weighted\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred_part3, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m,sample_weight\u001b[38;5;241m=\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     78\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTV distance\u001b[39m\u001b[38;5;124m'\u001b[39m:tv_part3,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartial repair3\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m---> 79\u001b[0m new_row_total\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDI\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mDisparateImpact_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred_total\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     80\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 macro\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred_total, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m,sample_weight\u001b[38;5;241m=\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     81\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 micro\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred_total, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m,sample_weight\u001b[38;5;241m=\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     82\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 weighted\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_score(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred_total, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m,sample_weight\u001b[38;5;241m=\u001b[39mdf_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     83\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTV distance\u001b[39m\u001b[38;5;124m'\u001b[39m:tv_total,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal repair\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m#report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T\u001b[39;00m\n\u001b[0;32m     86\u001b[0m report \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([report,new_row\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT,new_row_base\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT,new_row_bary\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT,new_row_part3\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT,new_row_total\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#new_row_part2.to_frame().T,\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:301\u001b[0m, in \u001b[0;36mDisparateImpact_postprocess\u001b[1;34m(df_test, y_pred_tmp)\u001b[0m\n\u001b[0;32m    298\u001b[0m denominator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msum\u001b[39m(df_test_tmp[(df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m&\u001b[39m(df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28msum\u001b[39m(df_test_tmp[df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# if numerator==denominator: # to avoid zero division error\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m#     return 1\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumerator\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mdenominator\u001b[49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    clf=RandomForestClassifier(max_depth=5, random_state=0).fit(X_train[:,0:var_dim],y_train)\n",
    "\n",
    "    df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "    df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "\n",
    "    if len(x_list)>1:\n",
    "        df_test['X']=[tuple(df_test[x_list].values[r]) for r in range(df_test.shape[0])]\n",
    "        x_range=list(set(df_test['X']))\n",
    "        weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "        C=c_generate_higher(x_range,weight)\n",
    "    else:\n",
    "        df_test['X']=df_test[x_list]\n",
    "        x_range=list(set(df_test['X']))\n",
    "        C=c_generate(x_range)\n",
    "\n",
    "    bin=len(x_range)\n",
    "    var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "    dist=rdata_analysis(df_test,x_range,'X')\n",
    "    dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "    dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "    px=np.matrix(dist['x']).T\n",
    "    ptx=np.matrix(dist['t_x']).T\n",
    "    if np.any(dist['x_0']==0): \n",
    "        p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "    else:\n",
    "        p0=np.matrix(dist['x_0']).T \n",
    "    if np.any(dist['x_1']==0):\n",
    "        p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "    else:\n",
    "        p1=np.matrix(dist['x_1']).T \n",
    "    V=np.matrix(dist['v']).T\n",
    "\n",
    "    coupling_base=baseline(C,e,px,ptx,V,K)\n",
    "    coupling_bary=baseline(C,e,p0,p1,V,K)\n",
    "    # coupling_part2=partial_repair(C,e,px,ptx,V,1.0e-2,K)\n",
    "    coupling_part3=partial_repair(C,e,px,ptx,V,1.0e-3,K)\n",
    "    coupling_total=partial_repair(C,e,px,ptx,V,1.0e-5,K)\n",
    "    \n",
    "    tv_base=assess_tv(df_test,coupling_base,x_range,x_list,var_list)\n",
    "    # tv_part2=assess_tv(df_test,coupling_part2,x_range,x_list,var_list)\n",
    "    tv_part3=assess_tv(df_test,coupling_part3,x_range,x_list,var_list)\n",
    "    tv_total=assess_tv(df_test,coupling_total,x_range,x_list,var_list)\n",
    "\n",
    "    y_pred=clf.predict(np.array(df_test[var_list]))\n",
    "    y_pred_base=postprocess(df_test,coupling_base,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_bary,tv_bary=postprocess_bary(df_test,coupling_bary,x_list,x_range,var_list,var_range,clf)\n",
    "    # y_pred_part2=postprocess(df_test,coupling_part2,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_part3=postprocess(df_test,coupling_part3,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_total=postprocess(df_test,coupling_total,x_list,x_range,var_list,var_range,clf)\n",
    "\n",
    "    new_row=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':sum(abs(dist['x_0']-dist['x_1']))/2,'method':'origin'})\n",
    "    new_row_base=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_base),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_base, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_base, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_base, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_base,'method':'baseline'})\n",
    "    new_row_bary=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_bary),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_bary, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_bary, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_bary, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_bary,'method':'barycentre'})\n",
    "    # new_row_part2=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part2),\n",
    "    #                     'f1 macro':f1_score(df_test['Y'], y_pred_part2, average='macro',sample_weight=df_test['W']),\n",
    "    #                     'f1 micro':f1_score(df_test['Y'], y_pred_part2, average='micro',sample_weight=df_test['W']),\n",
    "    #                     'f1 weighted':f1_score(df_test['Y'], y_pred_part2, average='weighted',sample_weight=df_test['W']),\n",
    "    #                     'TV distance':tv_part2,'method':'partial repair2'})\n",
    "    new_row_part3=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part3),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_part3, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_part3, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_part3, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_part3,'method':'partial repair3'})\n",
    "    new_row_total=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_total),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_total, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_total, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_total, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_total,'method':'total repair'})\n",
    "\n",
    "    #report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T\n",
    "    report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part3.to_frame().T,new_row_total.to_frame().T], ignore_index=True) #new_row_part2.to_frame().T,\n",
    "    #report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDisparateImpact_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred_total\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:301\u001b[0m, in \u001b[0;36mDisparateImpact_postprocess\u001b[1;34m(df_test, y_pred_tmp)\u001b[0m\n\u001b[0;32m    298\u001b[0m denominator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msum\u001b[39m(df_test_tmp[(df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m&\u001b[39m(df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28msum\u001b[39m(df_test_tmp[df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# if numerator==denominator: # to avoid zero division error\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m#     return 1\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumerator\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mdenominator\u001b[49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "DisparateImpact_postprocess(df_test,y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tmp=df_test[:]\n",
    "df_test_tmp.insert(loc=0, column='f', value=y_pred_total)\n",
    "numerator=sum(df_test_tmp[(df_test_tmp['S']==0)&(df_test_tmp['f']==1)]['W'])/sum(df_test_tmp[df_test_tmp['S']==0]['W'])\n",
    "denominator=sum(df_test_tmp[(df_test_tmp['S']==1)&(df_test_tmp['f']==1)]['W'])/sum(df_test_tmp[df_test_tmp['S']==1]['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "3        4\n",
       "5       29\n",
       "7       76\n",
       "        ..\n",
       "2096     3\n",
       "2099     4\n",
       "2100     1\n",
       "2114     1\n",
       "2125     1\n",
       "Name: W, Length: 804, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['S']==0]['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476469</td>\n",
       "      <td>0.677845</td>\n",
       "      <td>0.817884</td>\n",
       "      <td>0.788748</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.476469</td>\n",
       "      <td>0.677845</td>\n",
       "      <td>0.817884</td>\n",
       "      <td>0.788748</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816524</td>\n",
       "      <td>0.51392</td>\n",
       "      <td>0.597226</td>\n",
       "      <td>0.618989</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785138</td>\n",
       "      <td>0.657732</td>\n",
       "      <td>0.786815</td>\n",
       "      <td>0.767481</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.792288</td>\n",
       "      <td>0.657744</td>\n",
       "      <td>0.786456</td>\n",
       "      <td>0.767334</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>total repair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DI  f1 macro  f1 micro f1 weighted TV distance           method\n",
       "0  0.476469  0.677845  0.817884    0.788748    0.213168           origin\n",
       "1  0.476469  0.677845  0.817884    0.788748    0.213168         baseline\n",
       "2  0.816524   0.51392  0.597226    0.618989    0.001553       barycentre\n",
       "3  0.785138  0.657732  0.786815    0.767481    0.012225  partial repair3\n",
       "4  0.792288  0.657744  0.786456    0.767334    0.000154     total repair"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.679841</td>\n",
       "      <td>0.819164</td>\n",
       "      <td>0.789879</td>\n",
       "      <td>0.205342</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.679841</td>\n",
       "      <td>0.819164</td>\n",
       "      <td>0.789879</td>\n",
       "      <td>0.205342</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.137156</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>0.646926</td>\n",
       "      <td>0.658234</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.612484</td>\n",
       "      <td>0.673078</td>\n",
       "      <td>0.807442</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.104571</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.753164</td>\n",
       "      <td>0.66123</td>\n",
       "      <td>0.788504</td>\n",
       "      <td>0.769415</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.41162</td>\n",
       "      <td>0.688898</td>\n",
       "      <td>0.823566</td>\n",
       "      <td>0.797154</td>\n",
       "      <td>0.196117</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.41162</td>\n",
       "      <td>0.688898</td>\n",
       "      <td>0.823566</td>\n",
       "      <td>0.797154</td>\n",
       "      <td>0.196117</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.76884</td>\n",
       "      <td>0.546791</td>\n",
       "      <td>0.640631</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.58569</td>\n",
       "      <td>0.678863</td>\n",
       "      <td>0.810155</td>\n",
       "      <td>0.787464</td>\n",
       "      <td>0.095489</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.717355</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.790295</td>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.422402</td>\n",
       "      <td>0.690242</td>\n",
       "      <td>0.819983</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.204332</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.422402</td>\n",
       "      <td>0.690242</td>\n",
       "      <td>0.819983</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.204332</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00141</td>\n",
       "      <td>0.493177</td>\n",
       "      <td>0.579823</td>\n",
       "      <td>0.602166</td>\n",
       "      <td>0.00319</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.66771</td>\n",
       "      <td>0.672772</td>\n",
       "      <td>0.797461</td>\n",
       "      <td>0.777827</td>\n",
       "      <td>0.100599</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.70988</td>\n",
       "      <td>0.671836</td>\n",
       "      <td>0.790961</td>\n",
       "      <td>0.774667</td>\n",
       "      <td>0.01243</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance           method\n",
       "0   0.422121  0.679841  0.819164    0.789879    0.205342           origin\n",
       "1   0.422121  0.679841  0.819164    0.789879    0.205342         baseline\n",
       "2   1.137156  0.548193  0.646926    0.658234    0.000095       barycentre\n",
       "3   0.612484  0.673078  0.807442    0.782275    0.104571  partial repair2\n",
       "4   0.753164   0.66123  0.788504    0.769415    0.012275  partial repair3\n",
       "5    0.41162  0.688898  0.823566    0.797154    0.196117           origin\n",
       "6    0.41162  0.688898  0.823566    0.797154    0.196117         baseline\n",
       "7    0.76884  0.546791  0.640631    0.655862     0.00162       barycentre\n",
       "8    0.58569  0.678863  0.810155    0.787464    0.095489  partial repair2\n",
       "9   0.717355  0.665875  0.790295    0.773712    0.012288  partial repair3\n",
       "10  0.422402  0.690242  0.819983    0.794504    0.204332           origin\n",
       "11  0.422402  0.690242  0.819983    0.794504    0.204332         baseline\n",
       "12   1.00141  0.493177  0.579823    0.602166     0.00319       barycentre\n",
       "13   0.66771  0.672772  0.797461    0.777827    0.100599  partial repair2\n",
       "14   0.70988  0.671836  0.790961    0.774667     0.01243  partial repair3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv(path+'/data/report_postprocess_bary'+str(pa)+'.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

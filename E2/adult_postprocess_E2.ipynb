{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from functions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=200\n",
    "e=0.01\n",
    "\n",
    "var_list=['hoursperweek','age','capitalgain','capitalloss' ,'education-num'] #\n",
    "var_dim=len(var_list)\n",
    "pa='sex'\n",
    "pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "messydata=pd.read_csv(path+'/data/adult_csv.csv',usecols=var_list+[pa,'class'])\n",
    "messydata=messydata.rename(columns={pa:'S','class':'Y'})\n",
    "messydata['S']=messydata['S'].replace(pa_dict)\n",
    "messydata['Y']=messydata['Y'].replace({'>50K':1,'<=50K':0})\n",
    "messydata=messydata[(messydata['S']==1)|(messydata['S']==0)]\n",
    "for col in var_list+['S','Y']:\n",
    "    messydata[col]=messydata[col].astype('category')\n",
    "messydata['W']=1\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "C:\\Users\\zhouq\\AppData\\Local\\Temp\\ipykernel_16100\\415012319.py:3: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n"
     ]
    }
   ],
   "source": [
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "    dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.08:\n",
    "        x_list+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00169936, 0.00505712, 0.01042136, 0.01955284, 0.01547848,\n",
       "       0.02843864, 0.03709922, 0.01345154, 0.32316449, 0.22271815,\n",
       "       0.04219729, 0.03277917, 0.16430531, 0.0543999 , 0.01707547,\n",
       "       0.01216166])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:165: RuntimeWarning: overflow encountered in exp\n",
      "  fun = lambda z: sum(tmp.item(i,j)*V.item(i)*np.exp(-z*V.item(i)) for i in I)+theta.item(j)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:166: RuntimeWarning: overflow encountered in exp\n",
      "  dfun = lambda z: -sum(tmp.item(i,j)*(V.item(i))**2*np.exp(-z*V.item(i)) for i in I)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:33: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  b=a-fun(a)/dfun(a)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_t=pd.concat([df_t,sub],ignore_index=True) #pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:196: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot=pd.pivot_table(rdata,index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:199: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot0=pd.pivot_table(rdata[rdata['S']==0],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n",
      "c:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:202: FutureWarning: The provided callable <function sum at 0x0000013A85D68B80> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot1=pd.pivot_table(rdata[rdata['S']==1],index=x_name,values=['W'],aggfunc=[np.sum],observed=False)[(\"sum\",'W')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# tv_part2=assess_tv(df_test,coupling_part2,x_range,x_list,var_list)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m tv_part3\u001b[38;5;241m=\u001b[39massess_tv(df_test,coupling_part3,x_range,x_list,var_list)\n\u001b[1;32m---> 45\u001b[0m tv_total\u001b[38;5;241m=\u001b[39m\u001b[43massess_tv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoupling_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray(df_test[var_list]))\n\u001b[0;32m     48\u001b[0m y_pred_base\u001b[38;5;241m=\u001b[39mpostprocess(df_test,coupling_base,x_list,x_range,var_list,var_range,clf)\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:332\u001b[0m, in \u001b[0;36massess_tv\u001b[1;34m(df, coupling_matrix, x_range, x_list, var_list)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massess_tv\u001b[39m(df,coupling_matrix,x_range,x_list,var_list):\n\u001b[1;32m--> 332\u001b[0m     df_project\u001b[38;5;241m=\u001b[39m\u001b[43mprojection_higher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoupling_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m     rdist\u001b[38;5;241m=\u001b[39mrdata_analysis(df_project,x_range,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mabs\u001b[39m(rdist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39mrdist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:257\u001b[0m, in \u001b[0;36mprojection_higher\u001b[1;34m(df, coupling_matrix, x_range, x_list, var_list)\u001b[0m\n\u001b[0;32m    255\u001b[0m     sub_dict\u001b[38;5;241m.\u001b[39mupdate({var:[orig[var]]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mbin\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m arg_list\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[0;32m    256\u001b[0m     sub\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39msub_dict, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mbin\u001b[39m)])\n\u001b[1;32m--> 257\u001b[0m     df_t\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43msub\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#pd.concat([df_t,samples_groupby(sub,x_list)], ignore_index=True)\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_t\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:189\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    187\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:466\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, copy)\u001b[0m\n\u001b[0;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[0;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m--> 466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    467\u001b[0m     ju\u001b[38;5;241m.\u001b[39mget_reindexed_values(empty_dtype\u001b[38;5;241m=\u001b[39mempty_dtype, upcasted_na\u001b[38;5;241m=\u001b[39mupcasted_na)\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[0;32m    469\u001b[0m ]\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m         t\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[0;32m    481\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:467\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[0;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[0;32m    466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 467\u001b[0m     \u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reindexed_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupcasted_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupcasted_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[0;32m    469\u001b[0m ]\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m         t\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[0;32m    481\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:440\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m upcasted_na\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_valid_na_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty_dtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;66;03m# note: always holds when self.block.dtype.kind == \"V\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m         blk_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m blk_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;66;03m# we want to avoid filling with np.nan if we are\u001b[39;00m\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# using None; we already know that we are all\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# nulls\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:371\u001b[0m, in \u001b[0;36mJoinUnit._is_valid_na_for\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_valid_na_for_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:371\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mis_valid_na_for_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:754\u001b[0m, in \u001b[0;36mis_valid_na_for_dtype\u001b[1;34m(obj, dtype)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miufc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# Numeric\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64))\n\u001b[1;32m--> 754\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# We allow pd.NA, None, np.nan in BooleanArray (same as IntervalDtype)\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_float(obj) \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m libmissing\u001b[38;5;241m.\u001b[39mNA\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m _dtype_str:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;66;03m# numpy string dtypes to avoid float np.nan\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    clf=RandomForestClassifier(max_depth=5, random_state=0).fit(X_train[:,0:var_dim],y_train)\n",
    "\n",
    "    df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "    df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "\n",
    "    if len(x_list)>1:\n",
    "        df_test['X']=[tuple(df_test[x_list].values[r]) for r in range(df_test.shape[0])]\n",
    "        x_range=sorted(set(df_test['X']))\n",
    "        weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "        C=c_generate_higher(x_range,weight)\n",
    "    else:\n",
    "        df_test['X']=df_test[x_list]\n",
    "        x_range=sorted(set(df_test['X']))\n",
    "        C=c_generate(x_range)\n",
    "\n",
    "    bin=len(x_range)\n",
    "    var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "    dist=rdata_analysis(df_test,x_range,'X')\n",
    "    dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "    dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "    px=np.matrix(dist['x']).T\n",
    "    ptx=np.matrix(dist['t_x']).T\n",
    "    if np.any(dist['x_0']==0): \n",
    "        p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "    else:\n",
    "        p0=np.matrix(dist['x_0']).T \n",
    "    if np.any(dist['x_1']==0):\n",
    "        p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "    else:\n",
    "        p1=np.matrix(dist['x_1']).T \n",
    "    V=np.matrix(dist['v']).T\n",
    "\n",
    "    coupling_base=baseline(C,e,px,ptx,V,K)\n",
    "    coupling_bary=baseline(C,e,p0,p1,V,K)\n",
    "    # coupling_part2=partial_repair(C,e,px,ptx,V,1.0e-2,K)\n",
    "    coupling_part3=partial_repair(C,e,px,ptx,V,1.0e-3,K)\n",
    "    coupling_total=partial_repair(C,e,px,ptx,V,1.0e-5,K)\n",
    "    \n",
    "    tv_base=assess_tv(df_test,coupling_base,x_range,x_list,var_list)\n",
    "    # tv_part2=assess_tv(df_test,coupling_part2,x_range,x_list,var_list)\n",
    "    tv_part3=assess_tv(df_test,coupling_part3,x_range,x_list,var_list)\n",
    "    tv_total=assess_tv(df_test,coupling_total,x_range,x_list,var_list)\n",
    "\n",
    "    y_pred=clf.predict(np.array(df_test[var_list]))\n",
    "    y_pred_base=postprocess(df_test,coupling_base,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_bary,tv_bary=postprocess_bary(df_test,coupling_bary,x_list,x_range,var_list,var_range,clf)\n",
    "    # y_pred_part2=postprocess(df_test,coupling_part2,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_part3=postprocess(df_test,coupling_part3,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_total=postprocess(df_test,coupling_total,x_list,x_range,var_list,var_range,clf)\n",
    "\n",
    "    new_row=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':sum(abs(dist['x_0']-dist['x_1']))/2,'method':'origin'})\n",
    "    new_row_base=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_base),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_base, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_base, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_base, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_base,'method':'baseline'})\n",
    "    new_row_bary=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_bary),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_bary, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_bary, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_bary, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_bary,'method':'barycentre'})\n",
    "    # new_row_part2=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part2),\n",
    "    #                     'f1 macro':f1_score(df_test['Y'], y_pred_part2, average='macro',sample_weight=df_test['W']),\n",
    "    #                     'f1 micro':f1_score(df_test['Y'], y_pred_part2, average='micro',sample_weight=df_test['W']),\n",
    "    #                     'f1 weighted':f1_score(df_test['Y'], y_pred_part2, average='weighted',sample_weight=df_test['W']),\n",
    "    #                     'TV distance':tv_part2,'method':'partial repair2'})\n",
    "    new_row_part3=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part3),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_part3, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_part3, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_part3, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_part3,'method':'partial repair3'})\n",
    "    new_row_total=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_total),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_total, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_total, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_total, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_total,'method':'total repair'})\n",
    "\n",
    "    #report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T\n",
    "    report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part3.to_frame().T,new_row_total.to_frame().T], ignore_index=True) #new_row_part2.to_frame().T,\n",
    "    #report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDisparateImpact_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred_total\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhouq\\Documents\\OT_Debiasing\\E2\\functions.py:301\u001b[0m, in \u001b[0;36mDisparateImpact_postprocess\u001b[1;34m(df_test, y_pred_tmp)\u001b[0m\n\u001b[0;32m    298\u001b[0m denominator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msum\u001b[39m(df_test_tmp[(df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m&\u001b[39m(df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28msum\u001b[39m(df_test_tmp[df_test_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# if numerator==denominator: # to avoid zero division error\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m#     return 1\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumerator\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mdenominator\u001b[49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "DisparateImpact_postprocess(df_test,y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tmp=df_test[:]\n",
    "df_test_tmp.insert(loc=0, column='f', value=y_pred_total)\n",
    "numerator=sum(df_test_tmp[(df_test_tmp['S']==0)&(df_test_tmp['f']==1)]['W'])/sum(df_test_tmp[df_test_tmp['S']==0]['W'])\n",
    "denominator=sum(df_test_tmp[(df_test_tmp['S']==1)&(df_test_tmp['f']==1)]['W'])/sum(df_test_tmp[df_test_tmp['S']==1]['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "3        4\n",
       "5       29\n",
       "7       76\n",
       "        ..\n",
       "2096     3\n",
       "2099     4\n",
       "2100     1\n",
       "2114     1\n",
       "2125     1\n",
       "Name: W, Length: 804, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['S']==0]['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476469</td>\n",
       "      <td>0.677845</td>\n",
       "      <td>0.817884</td>\n",
       "      <td>0.788748</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.476469</td>\n",
       "      <td>0.677845</td>\n",
       "      <td>0.817884</td>\n",
       "      <td>0.788748</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816524</td>\n",
       "      <td>0.51392</td>\n",
       "      <td>0.597226</td>\n",
       "      <td>0.618989</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785138</td>\n",
       "      <td>0.657732</td>\n",
       "      <td>0.786815</td>\n",
       "      <td>0.767481</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.792288</td>\n",
       "      <td>0.657744</td>\n",
       "      <td>0.786456</td>\n",
       "      <td>0.767334</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>total repair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DI  f1 macro  f1 micro f1 weighted TV distance           method\n",
       "0  0.476469  0.677845  0.817884    0.788748    0.213168           origin\n",
       "1  0.476469  0.677845  0.817884    0.788748    0.213168         baseline\n",
       "2  0.816524   0.51392  0.597226    0.618989    0.001553       barycentre\n",
       "3  0.785138  0.657732  0.786815    0.767481    0.012225  partial repair3\n",
       "4  0.792288  0.657744  0.786456    0.767334    0.000154     total repair"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.679841</td>\n",
       "      <td>0.819164</td>\n",
       "      <td>0.789879</td>\n",
       "      <td>0.205342</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.679841</td>\n",
       "      <td>0.819164</td>\n",
       "      <td>0.789879</td>\n",
       "      <td>0.205342</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.137156</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>0.646926</td>\n",
       "      <td>0.658234</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.612484</td>\n",
       "      <td>0.673078</td>\n",
       "      <td>0.807442</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.104571</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.753164</td>\n",
       "      <td>0.66123</td>\n",
       "      <td>0.788504</td>\n",
       "      <td>0.769415</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.41162</td>\n",
       "      <td>0.688898</td>\n",
       "      <td>0.823566</td>\n",
       "      <td>0.797154</td>\n",
       "      <td>0.196117</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.41162</td>\n",
       "      <td>0.688898</td>\n",
       "      <td>0.823566</td>\n",
       "      <td>0.797154</td>\n",
       "      <td>0.196117</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.76884</td>\n",
       "      <td>0.546791</td>\n",
       "      <td>0.640631</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.58569</td>\n",
       "      <td>0.678863</td>\n",
       "      <td>0.810155</td>\n",
       "      <td>0.787464</td>\n",
       "      <td>0.095489</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.717355</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.790295</td>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.422402</td>\n",
       "      <td>0.690242</td>\n",
       "      <td>0.819983</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.204332</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.422402</td>\n",
       "      <td>0.690242</td>\n",
       "      <td>0.819983</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.204332</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00141</td>\n",
       "      <td>0.493177</td>\n",
       "      <td>0.579823</td>\n",
       "      <td>0.602166</td>\n",
       "      <td>0.00319</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.66771</td>\n",
       "      <td>0.672772</td>\n",
       "      <td>0.797461</td>\n",
       "      <td>0.777827</td>\n",
       "      <td>0.100599</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.70988</td>\n",
       "      <td>0.671836</td>\n",
       "      <td>0.790961</td>\n",
       "      <td>0.774667</td>\n",
       "      <td>0.01243</td>\n",
       "      <td>partial repair3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DI  f1 macro  f1 micro f1 weighted TV distance           method\n",
       "0   0.422121  0.679841  0.819164    0.789879    0.205342           origin\n",
       "1   0.422121  0.679841  0.819164    0.789879    0.205342         baseline\n",
       "2   1.137156  0.548193  0.646926    0.658234    0.000095       barycentre\n",
       "3   0.612484  0.673078  0.807442    0.782275    0.104571  partial repair2\n",
       "4   0.753164   0.66123  0.788504    0.769415    0.012275  partial repair3\n",
       "5    0.41162  0.688898  0.823566    0.797154    0.196117           origin\n",
       "6    0.41162  0.688898  0.823566    0.797154    0.196117         baseline\n",
       "7    0.76884  0.546791  0.640631    0.655862     0.00162       barycentre\n",
       "8    0.58569  0.678863  0.810155    0.787464    0.095489  partial repair2\n",
       "9   0.717355  0.665875  0.790295    0.773712    0.012288  partial repair3\n",
       "10  0.422402  0.690242  0.819983    0.794504    0.204332           origin\n",
       "11  0.422402  0.690242  0.819983    0.794504    0.204332         baseline\n",
       "12   1.00141  0.493177  0.579823    0.602166     0.00319       barycentre\n",
       "13   0.66771  0.672772  0.797461    0.777827    0.100599  partial repair2\n",
       "14   0.70988  0.671836  0.790961    0.774667     0.01243  partial repair3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv(path+'/data/report_postprocess_bary'+str(pa)+'.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

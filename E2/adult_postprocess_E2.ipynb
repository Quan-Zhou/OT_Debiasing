{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from aif360.datasets import BinaryLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhouq\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from functions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=200\n",
    "e=0.01\n",
    "\n",
    "var_list=['hoursperweek','age','capitalgain','capitalloss' ,'education-num'] #\n",
    "var_dim=len(var_list)\n",
    "pa='race' #'sex'\n",
    "pa_dict={'Male':1,'Female':0,'White':1,'Black':0}\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "messydata=pd.read_csv(path+'/data/adult_csv.csv',usecols=var_list+[pa,'class'])\n",
    "messydata=messydata.rename(columns={pa:'S','class':'Y'})\n",
    "messydata['S']=messydata['S'].replace(pa_dict)\n",
    "messydata['Y']=messydata['Y'].replace({'>50K':1,'<=50K':0})\n",
    "messydata=messydata[(messydata['S']==1)|(messydata['S']==0)]\n",
    "for col in var_list+['S','Y']:\n",
    "    messydata[col]=messydata[col].astype('category')\n",
    "messydata['W']=1\n",
    "X=messydata[var_list+['S','W']].to_numpy() # [X,S,W]\n",
    "y=messydata['Y'].to_numpy() #[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_dist=dict()\n",
    "for x_name in var_list:\n",
    "    x_range_single=list(pd.pivot_table(messydata,index=x_name,values=['W'])[('W')].index) \n",
    "    dist=rdata_analysis(messydata,x_range_single,x_name)\n",
    "    tv_dist[x_name]=sum(abs(dist['x_0']-dist['x_1']))/2\n",
    "x_list=[]\n",
    "for key,val in tv_dist.items():\n",
    "    if val>0.08:\n",
    "        x_list+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "report=pd.DataFrame(columns=['DI','f1 macro','f1 micro','f1 weighted','TV distance','method'])\n",
    "for ignore in range(2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    clf=RandomForestClassifier(max_depth=5, random_state=0).fit(X_train[:,0:var_dim],y_train)\n",
    "\n",
    "    df_test=pd.DataFrame(np.concatenate((X_test,y_test.reshape(-1,1)), axis=1),columns=var_list+['S','W','Y'])\n",
    "    df_test=df_test.groupby(by=var_list+['S','Y'],as_index=False).sum()\n",
    "\n",
    "    if len(x_list)>1:\n",
    "        df_test['X']=[tuple(df_test[x_list].values[r]) for r in range(df_test.shape[0])]\n",
    "        x_range=sorted(set(df_test['X']))\n",
    "        weight=list(1/(df_test[x_list].max()-df_test[x_list].min())) # because 'education-num' range from 1 to 16 while others 1 to 4\n",
    "        C=c_generate_higher(x_range,weight)\n",
    "    else:\n",
    "        df_test['X']=df_test[x_list]\n",
    "        x_range=sorted(set(df_test['X']))\n",
    "        C=c_generate(x_range)\n",
    "\n",
    "    bin=len(x_range)\n",
    "    var_range=list(pd.pivot_table(df_test,index=var_list,values=['S','W','Y']).index)\n",
    "    dist=rdata_analysis(df_test,x_range,'X')\n",
    "    dist['t_x']=dist['x'] # #dist['x'] #dist['x_0']*0.5+dist['x_1']*0.5 \n",
    "    dist['v']=[(dist['x_0'][i]-dist['x_1'][i])/dist['x'][i] for i in range(bin)]\n",
    "    px=np.matrix(dist['x']).T\n",
    "    ptx=np.matrix(dist['t_x']).T\n",
    "    if np.any(dist['x_0']==0): \n",
    "        p0=np.matrix((dist['x_0']+1.0e-9)/sum(dist['x_0']+1.0e-9)).T\n",
    "    else:\n",
    "        p0=np.matrix(dist['x_0']).T \n",
    "    if np.any(dist['x_1']==0):\n",
    "        p1=np.matrix((dist['x_1']+1.0e-9)/sum(dist['x_1']+1.0e-9)).T\n",
    "    else:\n",
    "        p1=np.matrix(dist['x_1']).T \n",
    "    V=np.matrix(dist['v']).T\n",
    "\n",
    "    coupling_base=baseline(C,e,px,ptx,V,K)\n",
    "    coupling_bary=baseline(C,e,p0,p1,V,K)\n",
    "    coupling_part2=partial_repair(C,e,px,ptx,V,1.0e-3,K)\n",
    "    # coupling_part3=partial_repair(C,e,px,ptx,V,1.0e-3,K)\n",
    "    # coupling_total=partial_repair(C,e,px,ptx,V,1.0e-5,K)\n",
    "    # test_RW=reweighting(df_test)\n",
    "    \n",
    "    tv_base=assess_tv(df_test,coupling_base,x_range,x_list,var_list)\n",
    "    tv_part2=assess_tv(df_test,coupling_part2,x_range,x_list,var_list)\n",
    "    # tv_part3=assess_tv(df_test,coupling_part3,x_range,x_list,var_list)\n",
    "    # tv_total=assess_tv(df_test,coupling_total,x_range,x_list,var_list)\n",
    "    # tv_RW=assess_tv(test_RW,[],x_range,x_list,var_list)\n",
    "\n",
    "    y_pred=clf.predict(np.array(df_test[var_list]))\n",
    "    y_pred_base=postprocess(df_test,coupling_base,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_bary,tv_bary=postprocess_bary(df_test,coupling_bary,x_list,x_range,var_list,var_range,clf)\n",
    "    y_pred_part2=postprocess(df_test,coupling_part2,x_list,x_range,var_list,var_range,clf)\n",
    "    # y_pred_part3=postprocess(df_test,coupling_part3,x_list,x_range,var_list,var_range,clf)\n",
    "    # y_pred_total=postprocess(df_test,coupling_total,x_list,x_range,var_list,var_range,clf)\n",
    "    # y_pred_RW=clf.predict(np.array(test_RW[var_list]))\n",
    "\n",
    "    new_row=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':sum(abs(dist['x_0']-dist['x_1']))/2,'method':'origin'})\n",
    "    new_row_base=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_base),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_base, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_base, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_base, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_base,'method':'baseline'})\n",
    "    new_row_bary=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_bary),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_bary, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_bary, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_bary, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_bary,'method':'barycentre'})\n",
    "    new_row_part2=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part2),\n",
    "                        'f1 macro':f1_score(df_test['Y'], y_pred_part2, average='macro',sample_weight=df_test['W']),\n",
    "                        'f1 micro':f1_score(df_test['Y'], y_pred_part2, average='micro',sample_weight=df_test['W']),\n",
    "                        'f1 weighted':f1_score(df_test['Y'], y_pred_part2, average='weighted',sample_weight=df_test['W']),\n",
    "                        'TV distance':tv_part2,'method':'partial repair2'})\n",
    "    # new_row_part3=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_part3),\n",
    "    #                     'f1 macro':f1_score(df_test['Y'], y_pred_part3, average='macro',sample_weight=df_test['W']),\n",
    "    #                     'f1 micro':f1_score(df_test['Y'], y_pred_part3, average='micro',sample_weight=df_test['W']),\n",
    "    #                     'f1 weighted':f1_score(df_test['Y'], y_pred_part3, average='weighted',sample_weight=df_test['W']),\n",
    "    #                     'TV distance':tv_part3,'method':'partial repair3'})\n",
    "    # new_row_total=pd.Series({'DI':DisparateImpact_postprocess(df_test,y_pred_total),\n",
    "    #                     'f1 macro':f1_score(df_test['Y'], y_pred_total, average='macro',sample_weight=df_test['W']),\n",
    "    #                     'f1 micro':f1_score(df_test['Y'], y_pred_total, average='micro',sample_weight=df_test['W']),\n",
    "    #                     'f1 weighted':f1_score(df_test['Y'], y_pred_total, average='weighted',sample_weight=df_test['W']),\n",
    "    #                     'TV distance':tv_total,'method':'total repair'})\n",
    "    # new_row_RW=pd.Series({'DI':DisparateImpact_postprocess(test_RW,y_pred_RW),\n",
    "    #                     'f1 macro':f1_score(test_RW['Y'], y_pred_RW, average='macro',sample_weight=test_RW['W']),\n",
    "    #                     'f1 micro':f1_score(test_RW['Y'], y_pred_RW, average='micro',sample_weight=test_RW['W']),\n",
    "    #                     'f1 weighted':f1_score(test_RW['Y'], y_pred_RW, average='weighted',sample_weight=test_RW['W']),\n",
    "    #                     'TV distance':tv_RW,'method':'reweighting'})\n",
    "    \n",
    "    report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part2.to_frame().T], ignore_index=True)\n",
    "    #report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T\n",
    "    # report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part3.to_frame().T,new_row_total.to_frame().T], ignore_index=True) #new_row_part2.to_frame().T,\n",
    "    #report = pd.concat([report,new_row.to_frame().T,new_row_base.to_frame().T,new_row_bary.to_frame().T,new_row_part2.to_frame().T,new_row_part3.to_frame().T,new_row_part4.to_frame().T], ignore_index=True) #,new_row_part4.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.353593</td>\n",
       "      <td>0.677809</td>\n",
       "      <td>0.81619</td>\n",
       "      <td>0.786812</td>\n",
       "      <td>0.19143</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.353593</td>\n",
       "      <td>0.677809</td>\n",
       "      <td>0.81619</td>\n",
       "      <td>0.786812</td>\n",
       "      <td>0.191351</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.73633</td>\n",
       "      <td>0.535094</td>\n",
       "      <td>0.702298</td>\n",
       "      <td>0.679023</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982744</td>\n",
       "      <td>0.627093</td>\n",
       "      <td>0.707142</td>\n",
       "      <td>0.716284</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.679819</td>\n",
       "      <td>0.675185</td>\n",
       "      <td>0.814967</td>\n",
       "      <td>0.785183</td>\n",
       "      <td>0.150419</td>\n",
       "      <td>reweighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.44555</td>\n",
       "      <td>0.690283</td>\n",
       "      <td>0.823241</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.195836</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.44555</td>\n",
       "      <td>0.690283</td>\n",
       "      <td>0.823241</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.931475</td>\n",
       "      <td>0.54916</td>\n",
       "      <td>0.701222</td>\n",
       "      <td>0.687002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.872677</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.753431</td>\n",
       "      <td>0.752417</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.77549</td>\n",
       "      <td>0.688621</td>\n",
       "      <td>0.822451</td>\n",
       "      <td>0.79609</td>\n",
       "      <td>0.160632</td>\n",
       "      <td>reweighting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DI  f1 macro  f1 micro f1 weighted TV distance           method\n",
       "0  0.353593  0.677809   0.81619    0.786812     0.19143           origin\n",
       "1  0.353593  0.677809   0.81619    0.786812    0.191351         baseline\n",
       "2   0.73633  0.535094  0.702298    0.679023    0.000049       barycentre\n",
       "3  0.982744  0.627093  0.707142    0.716284    0.025413  partial repair2\n",
       "4  0.679819  0.675185  0.814967    0.785183    0.150419      reweighting\n",
       "5   0.44555  0.690283  0.823241    0.797115    0.195836           origin\n",
       "6   0.44555  0.690283  0.823241    0.797115    0.195673         baseline\n",
       "7  0.931475   0.54916  0.701222    0.687002     0.00001       barycentre\n",
       "8  0.872677    0.6561  0.753431    0.752417    0.025543  partial repair2\n",
       "9   0.77549  0.688621  0.822451     0.79609    0.160632      reweighting"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DI</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 weighted</th>\n",
       "      <th>TV distance</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.449827</td>\n",
       "      <td>0.678789</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.789005</td>\n",
       "      <td>0.205545</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.449827</td>\n",
       "      <td>0.678789</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.789005</td>\n",
       "      <td>0.205545</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.04678</td>\n",
       "      <td>0.547657</td>\n",
       "      <td>0.641296</td>\n",
       "      <td>0.654991</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75701</td>\n",
       "      <td>0.658003</td>\n",
       "      <td>0.786661</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.895749</td>\n",
       "      <td>0.677025</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.787855</td>\n",
       "      <td>0.16003</td>\n",
       "      <td>reweighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.405739</td>\n",
       "      <td>0.678773</td>\n",
       "      <td>0.817219</td>\n",
       "      <td>0.787287</td>\n",
       "      <td>0.210459</td>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.405739</td>\n",
       "      <td>0.678773</td>\n",
       "      <td>0.817219</td>\n",
       "      <td>0.787287</td>\n",
       "      <td>0.210459</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.766167</td>\n",
       "      <td>0.538426</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.656396</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>barycentre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.757408</td>\n",
       "      <td>0.658621</td>\n",
       "      <td>0.786661</td>\n",
       "      <td>0.7662</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>partial repair2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.843715</td>\n",
       "      <td>0.674337</td>\n",
       "      <td>0.815176</td>\n",
       "      <td>0.784537</td>\n",
       "      <td>0.164602</td>\n",
       "      <td>reweighting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DI  f1 macro  f1 micro f1 weighted TV distance           method\n",
       "0  0.449827  0.678789  0.817833    0.789005    0.205545           origin\n",
       "1  0.449827  0.678789  0.817833    0.789005    0.205545         baseline\n",
       "2   1.04678  0.547657  0.641296    0.654991    0.000075       barycentre\n",
       "3   0.75701  0.658003  0.786661      0.7674    0.012038  partial repair2\n",
       "4  0.895749  0.677025  0.816853    0.787855     0.16003      reweighting\n",
       "5  0.405739  0.678773  0.817219    0.787287    0.210459           origin\n",
       "6  0.405739  0.678773  0.817219    0.787287    0.210459         baseline\n",
       "7  0.766167  0.538426  0.652301    0.656396    0.001311       barycentre\n",
       "8  0.757408  0.658621  0.786661      0.7662    0.012319  partial repair2\n",
       "9  0.843715  0.674337  0.815176    0.784537    0.164602      reweighting"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv(path+'/data/report_postprocess_bary'+str(pa)+'.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
